import os
import pandas as pd
from googleapiclient.discovery import build
import time
import random

# ========== CONFIG ==========
API_KEY = ''  # Set this in your environment
YOUTUBE = build('youtube', 'v3', developerKey=API_KEY)

SEARCH_TERMS = ['prefect ETL python', 'airbyte data engineering', 'analytics engineer', 'postgresql for data engineering', 'dbt data analytics tutorial', 'hex for data visualization']
PUBLISHED_AFTER = '2023-01-01T00:00:00Z'
MAX_RESULTS = 50       # Max results per page (max 50)
MAX_PAGES = 5         # Increase pages to deepen results
ORDER = 'relevance'        # 'date', 'relevance', 'viewCount', etc.



# ========== HELPER FUNCTIONS ==========

def retry_request(method, **kwargs):
    """
    Exponential backoff wrapper for API calls.
    """
    delay = 1
    for attempt in range(5):
        try:
            return method(**kwargs).execute()
        except Exception as e:
            print(f"⚠️ Error: {e}. Retrying in {delay}s...")
            time.sleep(delay)
            delay *= 2
    raise RuntimeError("Max retries exceeded.")


def search_videos(query, seen_ids):
    """
    Fetches videos for a search term, deduping by video ID.
    """
    items, token, page = [], None, 0
    while page < MAX_PAGES:
        resp = retry_request(
            YOUTUBE.search().list,
            q=query,
            part='id,snippet',
            type='video',
            publishedAfter=PUBLISHED_AFTER,
            maxResults=MAX_RESULTS,
            pageToken=token,
            order=ORDER
        )
        vids = resp.get('items', [])
        new = [v for v in vids if v['id']['videoId'] not in seen_ids]
        for v in new:
            seen_ids.add(v['id']['videoId'])
            items.append(v)
        token = resp.get('nextPageToken')
        if not token:
            break
        page += 1
        time.sleep(random.uniform(0.5, 1.5))  # jitter
    return items


def get_details(resource, part, id_list):
    """Generic details fetcher for videos or channels."""
    results = []
    for i in range(0, len(id_list), 50):
        resp = retry_request(
            getattr(YOUTUBE, resource)().list,
            part=part,
            **{ 'id': ','.join(id_list[i:i+50]) }
        )
        results.extend(resp.get('items', []))
        time.sleep(random.uniform(0.5, 1.5))
    return results


def build_dataframe(videos, channels_map=None):
    """Merge video + channel data (if provided)."""
    rows = []
    for v in videos:
        snip = v['snippet']
        stats = v.get('statistics', {})
        base = {
            'video_id': v['id'],
            'title': snip.get('title'),
            'description': snip.get('description'),
            'published_at': snip.get('publishedAt'),
            'view_count': int(stats.get('viewCount', 0)),
            'like_count': int(stats.get('likeCount', 0)),
            'comment_count': int(stats.get('commentCount', 0)),
            'channel_id': snip['channelId'],
        }
        if channels_map:
            base.update(channels_map.get(snip['channelId'], {}))
        rows.append(base)
    return pd.DataFrame(rows)

# ========== MAIN ==========

def main():
    seen_vids, all_videos = set(), []
    # Search
    for term in SEARCH_TERMS:
        print(f"Searching '{term}'...")
        found = search_videos(term, seen_vids)
        all_videos.extend(found)
    print(f"Total unique videos: {len(seen_vids)}")

    # Video details
    vid_ids = list(seen_vids)
    videos_full = get_details('videos', 'snippet,statistics,contentDetails', vid_ids)

    # Channel details (optional)
    chan_ids = list({v['snippet']['channelId'] for v in videos_full})
    channels = get_details('channels', 'snippet,statistics', chan_ids)
    chan_map = {c['id']:{
        'channel_title': c['snippet']['title'],
        'subscriber_count': int(c['statistics'].get('subscriberCount', 0))
    } for c in channels}

    df = build_dataframe(videos_full, chan_map)
    df.sort_values('view_count', ascending=False, inplace=True)
    fn = 'Nezzar_results.csv'
    df.to_csv(fn, index=False)
    print(f"Saved results to {fn}")

if __name__ == '__main__':
    main()
